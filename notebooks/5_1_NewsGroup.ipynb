{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "5-1 NewsGroup.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/ML-Class/blob/main/notebooks/5_1_NewsGroup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwWxzOte1L_U"
      },
      "source": [
        "## 作業\n",
        "1. string = ['He do love her and He does not loves he']  \n",
        "請將string用CountVectorizer編碼並將ngram_range=(1,2)來觀察結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "kgYwlIpw1L_Z",
        "outputId": "8711f064-20d7-4cba-ef31-1146e15613d9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "# plt.rcParams['font.sans-serif'] = ['DFKai-sb'] \n",
        "# plt.rcParams['axes.unicode_minus'] = False\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "string = ['He do love her and He does not loves he']\n",
        "cv = CountVectorizer(ngram_range=(1,2))\n",
        "bow = cv.fit_transform(string)\n",
        "df_bow = pd.DataFrame(bow.toarray(), columns=cv.get_feature_names())\n",
        "df_bow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>and he</th>\n",
              "      <th>do</th>\n",
              "      <th>do love</th>\n",
              "      <th>does</th>\n",
              "      <th>does not</th>\n",
              "      <th>he</th>\n",
              "      <th>he do</th>\n",
              "      <th>he does</th>\n",
              "      <th>her</th>\n",
              "      <th>her and</th>\n",
              "      <th>love</th>\n",
              "      <th>love her</th>\n",
              "      <th>loves</th>\n",
              "      <th>loves he</th>\n",
              "      <th>not</th>\n",
              "      <th>not loves</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   and  and he  do  do love  does  ...  love her  loves  loves he  not  not loves\n",
              "0    1       1   1        1     1  ...         1      1         1    1          1\n",
              "\n",
              "[1 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVaBOy511L_a"
      },
      "source": [
        "2. 用本章例子進行主題探索，將主題的數量設為3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "nGeKS94D1L_b",
        "outputId": "ef23c683-7a81-4aa8-920e-793471a88d67"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "model_pl = make_pipeline(\n",
        "    CountVectorizer(stop_words='english', max_df=0.4),\n",
        "    LatentDirichletAllocation(n_components=3)\n",
        ")\n",
        "X_topics = model_pl.fit_transform(train['data'])\n",
        "lda = model_pl.named_steps['latentdirichletallocation']\n",
        "cv = model_pl.named_steps['countvectorizer']\n",
        "\n",
        "n_topics = 3\n",
        "n_words = 8\n",
        "\n",
        "words = {}\n",
        "for topic in range(n_topics):\n",
        "    word = pd.DataFrame(lda.components_[topic], index=cv.get_feature_names()).\\\n",
        "            sort_values(by=0, ascending=False)[:n_words].index.tolist()\n",
        "    words[f'主題{topic+1}'] = word\n",
        "pd.DataFrame(words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>主題1</th>\n",
              "      <th>主題2</th>\n",
              "      <th>主題3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>graphics</td>\n",
              "      <td>pitt</td>\n",
              "      <td>god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image</td>\n",
              "      <td>cs</td>\n",
              "      <td>people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>university</td>\n",
              "      <td>msg</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>posting</td>\n",
              "      <td>gordon</td>\n",
              "      <td>don</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>file</td>\n",
              "      <td>banks</td>\n",
              "      <td>jesus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>host</td>\n",
              "      <td>medical</td>\n",
              "      <td>does</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>use</td>\n",
              "      <td>university</td>\n",
              "      <td>just</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>software</td>\n",
              "      <td>geb</td>\n",
              "      <td>say</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          主題1         主題2     主題3\n",
              "0    graphics        pitt     god\n",
              "1       image          cs  people\n",
              "2  university         msg   think\n",
              "3     posting      gordon     don\n",
              "4        file       banks   jesus\n",
              "5        host     medical    does\n",
              "6         use  university    just\n",
              "7    software         geb     say"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjv-2aPT1L_c"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}