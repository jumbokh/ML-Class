{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "4-9 Telcom Customer Churn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/ML-Class/blob/main/notebooks/4_9_Telcom_Customer_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87-LCtlV11Tj"
      },
      "source": [
        "## 作業\n",
        "1. 請用本章資料，並用向下取樣法，再用網格搜尋來進行機器學習的挑選。\n",
        "\n",
        "'model':[RandomForestClassifier(), AdaBoostClassifier(), \n",
        "                       BaggingClassifier(), XGBClassifier()]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh4fEZaD11Tm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_csv('IBM_Churn.csv')\n",
        "df['TotalCharges'] = df['TotalCharges'].replace(' ',0)\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
        "df['Churn'] = df['Churn'].replace({'No':0, 'Yes':1})\n",
        "df.drop('customerID', axis=1, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "X_col_cat = X.select_dtypes(include = 'object').columns\n",
        "X_col_num = X.select_dtypes(exclude = 'object').columns\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "data_pl = ColumnTransformer([\n",
        "    ('num', StandardScaler(), X_col_num),\n",
        "    ('cat', OneHotEncoder(), X_col_cat)\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "KSo3M42K11To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4cd41f7-4267-4058-969e-9f380fc74496"
      },
      "source": [
        "from imblearn.pipeline import Pipeline as Pipeline_im\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "model_pl = Pipeline_im([\n",
        "    ('preprocess', data_pl),\n",
        "    ('resample', RandomUnderSampler(replacement=False)),\n",
        "    ('model', LogisticRegression())\n",
        "])\n",
        "np.random.seed(42)\n",
        "param_grid = {'model':[RandomForestClassifier(), AdaBoostClassifier(), \n",
        "                       BaggingClassifier(), XGBClassifier()]}\n",
        "gs = GridSearchCV(model_pl, param_grid=param_grid,\n",
        "                  cv=5, return_train_score=True)\n",
        "gs.fit(X_train, y_train)\n",
        "score = gs.best_estimator_.score(X_test, y_test)\n",
        "print('最佳預測參數', gs.best_params_)\n",
        "print('訓練集交叉驗證的最佳結果', gs.best_score_.round(3))\n",
        "print('測試集的結果', score.round(3))\n",
        "y_pred = gs.best_estimator_.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('綜合報告')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "最佳預測參數 {'model': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)}\n",
            "訓練集交叉驗證的最佳結果 0.744\n",
            "測試集的結果 0.756\n",
            "[[1136  403]\n",
            " [ 113  461]]\n",
            "綜合報告\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.74      0.81      1539\n",
            "           1       0.53      0.80      0.64       574\n",
            "\n",
            "    accuracy                           0.76      2113\n",
            "   macro avg       0.72      0.77      0.73      2113\n",
            "weighted avg       0.81      0.76      0.77      2113\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}